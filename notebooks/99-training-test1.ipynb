{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install pandas pytorch-lightning torch-metrics scikit-learn scikit-image numpy matplotlib tqdm jupyterlab captum wandb opencv-python-headless timm seaborn plotly umap-learnm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from mouse_facial_expressions.paths import *\n",
    "\n",
    "project_dir = Path('..').resolve()\n",
    "frames_dir = Path(get_extracted_frames_folder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>video</th>\n",
       "      <th>date</th>\n",
       "      <th>logged_video_start_time</th>\n",
       "      <th>mouse</th>\n",
       "      <th>stage</th>\n",
       "      <th>treatment</th>\n",
       "      <th>pre_experiment_cage</th>\n",
       "      <th>injection_time</th>\n",
       "      <th>injection_date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220614_152021...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>15:21:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>11:21:00</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220614_152021...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>15:21:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>11:21:00</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220614_152021...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>15:21:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>11:21:00</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220614_152021...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>15:21:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>11:21:00</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220614_152021...</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>15:21:00</td>\n",
       "      <td>5</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>11:21:00</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220617_154642...</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>15:47:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>saline</td>\n",
       "      <td>8</td>\n",
       "      <td>11:47:00</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9489</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220617_154642...</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>15:47:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>saline</td>\n",
       "      <td>8</td>\n",
       "      <td>11:47:00</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220617_154642...</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>15:47:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>saline</td>\n",
       "      <td>8</td>\n",
       "      <td>11:47:00</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220617_154642...</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>15:47:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>saline</td>\n",
       "      <td>8</td>\n",
       "      <td>11:47:00</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>/home/andre/berlin2022/datasets/CUv2/resized-i...</td>\n",
       "      <td>Basler_acA1920-40um__23999063__20220617_154642...</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>15:47:00</td>\n",
       "      <td>16</td>\n",
       "      <td>4h post injection</td>\n",
       "      <td>saline</td>\n",
       "      <td>8</td>\n",
       "      <td>11:47:00</td>\n",
       "      <td>2022-06-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>897 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  \\\n",
       "600   /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "601   /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "602   /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "603   /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "604   /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "...                                                 ...   \n",
       "9488  /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "9489  /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "9490  /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "9491  /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "9492  /home/andre/berlin2022/datasets/CUv2/resized-i...   \n",
       "\n",
       "                                                  video        date  \\\n",
       "600   Basler_acA1920-40um__23999063__20220614_152021...  2022-06-14   \n",
       "601   Basler_acA1920-40um__23999063__20220614_152021...  2022-06-14   \n",
       "602   Basler_acA1920-40um__23999063__20220614_152021...  2022-06-14   \n",
       "603   Basler_acA1920-40um__23999063__20220614_152021...  2022-06-14   \n",
       "604   Basler_acA1920-40um__23999063__20220614_152021...  2022-06-14   \n",
       "...                                                 ...         ...   \n",
       "9488  Basler_acA1920-40um__23999063__20220617_154642...  2022-06-17   \n",
       "9489  Basler_acA1920-40um__23999063__20220617_154642...  2022-06-17   \n",
       "9490  Basler_acA1920-40um__23999063__20220617_154642...  2022-06-17   \n",
       "9491  Basler_acA1920-40um__23999063__20220617_154642...  2022-06-17   \n",
       "9492  Basler_acA1920-40um__23999063__20220617_154642...  2022-06-17   \n",
       "\n",
       "     logged_video_start_time  mouse              stage treatment  \\\n",
       "600                 15:21:00      5  4h post injection      high   \n",
       "601                 15:21:00      5  4h post injection      high   \n",
       "602                 15:21:00      5  4h post injection      high   \n",
       "603                 15:21:00      5  4h post injection      high   \n",
       "604                 15:21:00      5  4h post injection      high   \n",
       "...                      ...    ...                ...       ...   \n",
       "9488                15:47:00     16  4h post injection    saline   \n",
       "9489                15:47:00     16  4h post injection    saline   \n",
       "9490                15:47:00     16  4h post injection    saline   \n",
       "9491                15:47:00     16  4h post injection    saline   \n",
       "9492                15:47:00     16  4h post injection    saline   \n",
       "\n",
       "      pre_experiment_cage injection_time injection_date  label  \n",
       "600                     2       11:21:00     2022-06-14      1  \n",
       "601                     2       11:21:00     2022-06-14      1  \n",
       "602                     2       11:21:00     2022-06-14      1  \n",
       "603                     2       11:21:00     2022-06-14      1  \n",
       "604                     2       11:21:00     2022-06-14      1  \n",
       "...                   ...            ...            ...    ...  \n",
       "9488                    8       11:47:00     2022-06-17      0  \n",
       "9489                    8       11:47:00     2022-06-17      0  \n",
       "9490                    8       11:47:00     2022-06-17      0  \n",
       "9491                    8       11:47:00     2022-06-17      0  \n",
       "9492                    8       11:47:00     2022-06-17      0  \n",
       "\n",
       "[897 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def load_data():\n",
    "    dataset_path = Path('/home/andre/berlin2022/datasets').resolve() / 'CUv2'\n",
    "    treatments = pd.read_csv(dataset_path / 'treatments.csv')\n",
    "    videos = pd.read_csv(dataset_path / 'video-log.csv')\n",
    "    \n",
    "    # Get images\n",
    "    imagepaths = dataset_path.glob('resized-images/*/*.png')\n",
    "    \n",
    "    # Merge datasets\n",
    "    df = pd.DataFrame({'image': imagepaths})\n",
    "    def get_video_name_from_imagepath(imagepath):\n",
    "        m = re.match(\"(.*)_MGSframes\", imagepath.parts[-2])\n",
    "        return m.groups()[0] + '.mp4'\n",
    "    \n",
    "    df['video'] = df.image.apply(get_video_name_from_imagepath)\n",
    "    df = df.merge(videos, on='video')\n",
    "    df = df.merge(treatments, on='mouse')\n",
    "\n",
    "    # Filter\n",
    "    # df = df[df.stage != 'acclimation']  \n",
    "    df = df[df.mouse != 18] # control mouse appeared sick in videos\n",
    "    df = df[df.stage == '4h post injection']\n",
    "    df = df[df.treatment.isin(['high', 'saline'])]\n",
    "    \n",
    "    # Label everything a 1\n",
    "    df['label'] = np.ones(shape=df.shape[0], dtype=int)\n",
    "    \n",
    "    # Label control situations\n",
    "    df.loc[df.stage == 'preinjection', 'label'] = 0\n",
    "    df.loc[df.treatment == 'saline', 'label'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mouse</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>treatment</th>\n",
       "      <th>injection_time</th>\n",
       "      <th>notes</th>\n",
       "      <th>image</th>\n",
       "      <th>video</th>\n",
       "      <th>recording</th>\n",
       "      <th>camera</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>minutes</th>\n",
       "      <th>seconds</th>\n",
       "      <th>animal</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>discard</th>\n",
       "      <th>Notes</th>\n",
       "      <th>video_time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11703</th>\n",
       "      <td>m12</td>\n",
       "      <td>16 April 2022</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:00</td>\n",
       "      <td>approx timing</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m12_rec...</td>\n",
       "      <td>m12_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>m12</td>\n",
       "      <td>0:20</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>m4</td>\n",
       "      <td>11 January 2022</td>\n",
       "      <td>high</td>\n",
       "      <td>13:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m4_rec4...</td>\n",
       "      <td>m4_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>35</td>\n",
       "      <td>m4</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>re-recorded</td>\n",
       "      <td>17:22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33099</th>\n",
       "      <td>f1</td>\n",
       "      <td>13 November 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f1_rec4...</td>\n",
       "      <td>f1_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35429</th>\n",
       "      <td>f3</td>\n",
       "      <td>13 November 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f3_rec1...</td>\n",
       "      <td>f3_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>f3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6238</th>\n",
       "      <td>m7</td>\n",
       "      <td>25 March 2022</td>\n",
       "      <td>saline</td>\n",
       "      <td>11:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m7_rec4...</td>\n",
       "      <td>m7_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>m7</td>\n",
       "      <td>0:07</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>m5</td>\n",
       "      <td>11 January 2022</td>\n",
       "      <td>high</td>\n",
       "      <td>11:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m5_rec4...</td>\n",
       "      <td>m5_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>m5</td>\n",
       "      <td>0:07</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43538</th>\n",
       "      <td>f10</td>\n",
       "      <td>15 August 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f10_rec...</td>\n",
       "      <td>f10_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>f10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33100</th>\n",
       "      <td>f1</td>\n",
       "      <td>13 November 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f1_rec4...</td>\n",
       "      <td>f1_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>f1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16:20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46789</th>\n",
       "      <td>f12</td>\n",
       "      <td>25 October 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f12_rec...</td>\n",
       "      <td>f12_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>f12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40740</th>\n",
       "      <td>f8</td>\n",
       "      <td>25 October 22</td>\n",
       "      <td>high</td>\n",
       "      <td>13:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f8_rec4...</td>\n",
       "      <td>f8_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>f8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46814</th>\n",
       "      <td>f12</td>\n",
       "      <td>25 October 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f12_rec...</td>\n",
       "      <td>f12_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>f12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42981</th>\n",
       "      <td>f10</td>\n",
       "      <td>15 August 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f10_rec...</td>\n",
       "      <td>f10_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>f10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>m3</td>\n",
       "      <td>18 April 2022</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m3_rec1...</td>\n",
       "      <td>m3_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>14</td>\n",
       "      <td>m3</td>\n",
       "      <td>0:13</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12:36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62212</th>\n",
       "      <td>f31</td>\n",
       "      <td>24 November 22</td>\n",
       "      <td>high</td>\n",
       "      <td>14:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f31_rec...</td>\n",
       "      <td>f31_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>55</td>\n",
       "      <td>f31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18:47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51089</th>\n",
       "      <td>f15</td>\n",
       "      <td>16 December 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f15_rec...</td>\n",
       "      <td>f15_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>19</td>\n",
       "      <td>f15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>early stop (shorter)</td>\n",
       "      <td>12:39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43110</th>\n",
       "      <td>f10</td>\n",
       "      <td>15 August 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>12:08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f10_rec...</td>\n",
       "      <td>f10_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>46</td>\n",
       "      <td>f10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14882</th>\n",
       "      <td>m15</td>\n",
       "      <td>18 April 22</td>\n",
       "      <td>high</td>\n",
       "      <td>11:34</td>\n",
       "      <td>approx timing</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/m15_rec...</td>\n",
       "      <td>m15_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2022</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>16</td>\n",
       "      <td>m15</td>\n",
       "      <td>0:04</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62720</th>\n",
       "      <td>f32</td>\n",
       "      <td>24 November 22</td>\n",
       "      <td>saline</td>\n",
       "      <td>14:50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f32_rec...</td>\n",
       "      <td>f32_rec1_preinjection</td>\n",
       "      <td>1</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>f32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14:02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50871</th>\n",
       "      <td>f15</td>\n",
       "      <td>16 December 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f15_rec...</td>\n",
       "      <td>f15_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>35</td>\n",
       "      <td>f15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47070</th>\n",
       "      <td>f12</td>\n",
       "      <td>25 October 22</td>\n",
       "      <td>high</td>\n",
       "      <td>12:38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/backup/data/extracted_frames/20230627/f12_rec...</td>\n",
       "      <td>f12_rec4_4h-postinjection</td>\n",
       "      <td>4</td>\n",
       "      <td>Basler_acA1920-40um</td>\n",
       "      <td>2023</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>55</td>\n",
       "      <td>f12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17:29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mouse    date_of_birth treatment injection_time          notes  \\\n",
       "11703   m12    16 April 2022    saline          12:00  approx timing   \n",
       "3899     m4  11 January 2022      high          13:07            NaN   \n",
       "33099    f1   13 November 22    saline          12:23            NaN   \n",
       "35429    f3   13 November 22      high          12:53            NaN   \n",
       "6238     m7    25 March 2022    saline          11:50            NaN   \n",
       "4456     m5  11 January 2022      high          11:21            NaN   \n",
       "43538   f10     15 August 22    saline          12:08            NaN   \n",
       "33100    f1   13 November 22    saline          12:23            NaN   \n",
       "46789   f12    25 October 22      high          12:38            NaN   \n",
       "40740    f8    25 October 22      high          13:00            NaN   \n",
       "46814   f12    25 October 22      high          12:38            NaN   \n",
       "42981   f10     15 August 22    saline          12:08            NaN   \n",
       "2150     m3    18 April 2022    saline          12:52            NaN   \n",
       "62212   f31   24 November 22      high          14:34            NaN   \n",
       "51089   f15   16 December 22      high          12:44            NaN   \n",
       "43110   f10     15 August 22    saline          12:08            NaN   \n",
       "14882   m15      18 April 22      high          11:34  approx timing   \n",
       "62720   f32   24 November 22    saline          14:50            NaN   \n",
       "50871   f15   16 December 22      high          12:44            NaN   \n",
       "47070   f12    25 October 22      high          12:38            NaN   \n",
       "\n",
       "                                                   image  \\\n",
       "11703  /backup/data/extracted_frames/20230627/m12_rec...   \n",
       "3899   /backup/data/extracted_frames/20230627/m4_rec4...   \n",
       "33099  /backup/data/extracted_frames/20230627/f1_rec4...   \n",
       "35429  /backup/data/extracted_frames/20230627/f3_rec1...   \n",
       "6238   /backup/data/extracted_frames/20230627/m7_rec4...   \n",
       "4456   /backup/data/extracted_frames/20230627/m5_rec4...   \n",
       "43538  /backup/data/extracted_frames/20230627/f10_rec...   \n",
       "33100  /backup/data/extracted_frames/20230627/f1_rec4...   \n",
       "46789  /backup/data/extracted_frames/20230627/f12_rec...   \n",
       "40740  /backup/data/extracted_frames/20230627/f8_rec4...   \n",
       "46814  /backup/data/extracted_frames/20230627/f12_rec...   \n",
       "42981  /backup/data/extracted_frames/20230627/f10_rec...   \n",
       "2150   /backup/data/extracted_frames/20230627/m3_rec1...   \n",
       "62212  /backup/data/extracted_frames/20230627/f31_rec...   \n",
       "51089  /backup/data/extracted_frames/20230627/f15_rec...   \n",
       "43110  /backup/data/extracted_frames/20230627/f10_rec...   \n",
       "14882  /backup/data/extracted_frames/20230627/m15_rec...   \n",
       "62720  /backup/data/extracted_frames/20230627/f32_rec...   \n",
       "50871  /backup/data/extracted_frames/20230627/f15_rec...   \n",
       "47070  /backup/data/extracted_frames/20230627/f12_rec...   \n",
       "\n",
       "                           video  recording               camera  year  ...  \\\n",
       "11703      m12_rec1_preinjection          1  Basler_acA1920-40um  2022  ...   \n",
       "3899    m4_rec4_4h-postinjection          4  Basler_acA1920-40um  2022  ...   \n",
       "33099   f1_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "35429       f3_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "6238    m7_rec4_4h-postinjection          4  Basler_acA1920-40um  2022  ...   \n",
       "4456    m5_rec4_4h-postinjection          4  Basler_acA1920-40um  2022  ...   \n",
       "43538  f10_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "33100   f1_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "46789      f12_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "40740   f8_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "46814      f12_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "42981      f10_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "2150        m3_rec1_preinjection          1  Basler_acA1920-40um  2022  ...   \n",
       "62212  f31_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "51089      f15_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "43110      f10_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "14882  m15_rec4_4h-postinjection          4  Basler_acA1920-40um  2022  ...   \n",
       "62720      f32_rec1_preinjection          1  Basler_acA1920-40um  2023  ...   \n",
       "50871  f15_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "47070  f12_rec4_4h-postinjection          4  Basler_acA1920-40um  2023  ...   \n",
       "\n",
       "       hour  minutes  seconds  animal  start  end discard  \\\n",
       "11703    11       39        9     m12   0:20   -1     NaN   \n",
       "3899     17       22       35      m4      0   -1     NaN   \n",
       "33099    16       20       23      f1    NaN  NaN     NaN   \n",
       "35429    12       37       54      f3    NaN  NaN     NaN   \n",
       "6238     15       48       29      m7   0:07   -1     NaN   \n",
       "4456     15       20       21      m5   0:07   -1     NaN   \n",
       "43538    16       59       53     f10    NaN  NaN     NaN   \n",
       "33100    16       20       23      f1    NaN  NaN     NaN   \n",
       "46789    12       21       10     f12    NaN  NaN     NaN   \n",
       "40740    17       46        1      f8    NaN  NaN     NaN   \n",
       "46814    12       21       10     f12    NaN  NaN     NaN   \n",
       "42981    11       52       46     f10    NaN  NaN     NaN   \n",
       "2150     12       36       14      m3   0:13   -1     NaN   \n",
       "62212    18       47       55     f31    NaN  NaN     NaN   \n",
       "51089    12       39       19     f15    NaN  NaN     1.0   \n",
       "43110    11       52       46     f10    NaN  NaN     NaN   \n",
       "14882    15       34       16     m15   0:04   -1     NaN   \n",
       "62720    14        2       20     f32    NaN  NaN     NaN   \n",
       "50871    17       19       35     f15    NaN  NaN     NaN   \n",
       "47070    17       29       55     f12    NaN  NaN     NaN   \n",
       "\n",
       "                      Notes  video_time label  \n",
       "11703                   NaN       11:39     0  \n",
       "3899           re-recorded        17:22     1  \n",
       "33099                   NaN       16:20     0  \n",
       "35429                   NaN       12:37     0  \n",
       "6238                    NaN       15:48     0  \n",
       "4456                    NaN       15:20     1  \n",
       "43538                   NaN       16:59     0  \n",
       "33100                   NaN       16:20     0  \n",
       "46789                   NaN       12:21     0  \n",
       "40740                   NaN       17:46     1  \n",
       "46814                   NaN       12:21     0  \n",
       "42981                   NaN       11:52     0  \n",
       "2150                    NaN       12:36     0  \n",
       "62212                   NaN       18:47     1  \n",
       "51089  early stop (shorter)       12:39     0  \n",
       "43110                   NaN       11:52     0  \n",
       "14882                   NaN       15:34     1  \n",
       "62720                   NaN       14:02     0  \n",
       "50871                   NaN       17:19     1  \n",
       "47070                   NaN       17:29     1  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatments_df = pd.read_csv(project_dir / 'data/raw/treatments_20230627.csv')\n",
    "\n",
    "frames_folder_df = pd.DataFrame(dict(image=list(frames_dir.glob('*/*.png'))))\n",
    "frames_folder_df['video'] = frames_folder_df.image.apply(lambda x: x.parts[-2])\n",
    "frames_folder_df['mouse'] = frames_folder_df.video.apply(lambda x: re.match('([mf]\\d+)', x).group(1))\n",
    "frames_folder_df['recording'] = frames_folder_df.video.apply(lambda x: int(re.match('.*rec(\\d+)', x).group(1)))\n",
    "\n",
    "raw_videos_df = pd.read_csv(project_dir / 'data/raw/raw_videos_20230627.csv')\n",
    "raw_videos_df.recording = raw_videos_df.recording.fillna(-1).astype(int)\n",
    "raw_videos_df['video_time'] = raw_videos_df.apply(lambda x: f\"{x.hour:02}:{x.minutes:02}\", axis=1)\n",
    "raw_videos_df['mouse'] = raw_videos_df.animal\n",
    "\n",
    "combined_df = treatments_df.merge(frames_folder_df, how='left', on='mouse')\n",
    "combined_df = combined_df.merge(raw_videos_df, how='left', on=['mouse', 'recording'])\n",
    "\n",
    "combined_df = combined_df[combined_df.mouse != 'm18']\n",
    "combined_df = combined_df[combined_df.treatment.isin(['high', 'saline'])]\n",
    "combined_df = combined_df[combined_df.recording.isin([1, 4])]\n",
    "\n",
    "# Label everything a 1\n",
    "combined_df['label'] = np.ones(shape=combined_df.shape[0], dtype=int)\n",
    "\n",
    "# Label control situations\n",
    "combined_df.loc[combined_df.recording == 1, 'label'] = 0\n",
    "combined_df.loc[combined_df.treatment == 'saline', 'label'] = 0\n",
    "\n",
    "combined_df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "from torchvision.transforms import (Compose, Normalize, RandAugment,\n",
    "                                    ToPILImage, ToTensor, TrivialAugmentWide)\n",
    "\n",
    "class FP(torch.nn.Module):    \n",
    "    def __call__(self, preds, target):\n",
    "        preds = torch.argmax(preds, 1)\n",
    "        values = torch.logical_and((target == 0), (preds == 1))\n",
    "        return torch.sum(values).int() \n",
    "\n",
    "class TP(torch.nn.Module):\n",
    "    def __call__(self, preds, target):\n",
    "        preds = torch.argmax(preds, 1)\n",
    "        values = torch.logical_and((target == 1), (preds == 1))\n",
    "        return torch.sum(values).int()\n",
    "    \n",
    "class FN(torch.nn.Module):\n",
    "    def __call__(self, preds, target):\n",
    "        preds = torch.argmax(preds, 1)\n",
    "        values = torch.logical_and((target == 1), (preds == 0))\n",
    "        return torch.sum(values).int()\n",
    "    \n",
    "class TN(torch.nn.Module):\n",
    "    def __call__(self, preds, target):\n",
    "        preds = torch.argmax(preds, 1)\n",
    "        values = torch.logical_and((target == 0), (preds == 0))\n",
    "        return torch.sum(values).int()\n",
    "    \n",
    "class DeepSet(pl.LightningModule):\n",
    "    def __init__(self, config, class_weights):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model_ = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "        # for parameter in self.model_.parameters():\n",
    "        #     parameter.requires_grad = False\n",
    "            \n",
    "        in_features = self.model_.fc.in_features\n",
    "        n_classes = 2 \n",
    "        features = 1\n",
    "        self.model_.fc = torch.nn.Linear(in_features, features)\n",
    "        self.fc = torch.nn.Linear(features, n_classes) # The purpose of this layer is really just to add bias\n",
    "        self.criterion = torch.nn.CrossEntropyLoss(\n",
    "            weight=class_weights, label_smoothing=config['label_smoothing'])\n",
    "        \n",
    "        self.metrics = torch.nn.ModuleDict({\n",
    "            'accuracy': Accuracy(task='multiclass', num_classes=2),\n",
    "            'tn': TN(),\n",
    "            'fn': FN(),\n",
    "            'tp': TP(),\n",
    "            'fp': FP()\n",
    "        })\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        lr = self.config['learning_rate']\n",
    "        warmup_steps = self.config['warmup_steps']\n",
    "        warmup_decay = self.config['warmup_decay']\n",
    "        total_steps = self.config['total_steps']\n",
    "        optimizer = torch.optim.SGD(params=self.parameters(), lr=lr, momentum=0.9, weight_decay=warmup_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[\n",
    "                torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=warmup_decay, total_iters=warmup_steps), \n",
    "                torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, self.trainer.max_steps-warmup_steps),\n",
    "            ], \n",
    "            milestones=[warmup_steps]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def shared_step_(self, stage, batch, batch_idx):\n",
    "        x = batch['image'].float()\n",
    "        y = batch['label'].long()\n",
    "        \n",
    "        # Flatten (batch, set, images) -> (batch x set, images)\n",
    "        s = x.shape\n",
    "        x = x.flatten(0, 1)\n",
    "        \n",
    "        # Pass through model\n",
    "        z = self.model_(x)\n",
    "        \n",
    "        # Reshape into (batch x set, images) -> (batch, set, images)\n",
    "        z = z.reshape(*s[:2], z.shape[-1])\n",
    "        z = z.mean(dim=1) # Mean over each image (dims are batch, image, class preds)\n",
    "        \n",
    "        # Finally add bias\n",
    "        y_hat = self.fc(z)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(stage+\"_loss\", loss.item(), prog_bar=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for k in self.metrics:\n",
    "                self.log(stage+\"_\"+k, self.metrics[k](y_hat, y), prog_bar=True)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        cur_lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", cur_lr, prog_bar=True, on_step=True)\n",
    "        return self.shared_step_(\"train\", batch, batch_idx)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self.shared_step_(\"val\", batch, batch_idx)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self.shared_step_(\"test\", batch, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision\n",
    "import wandb\n",
    "from pytorch_lightning.callbacks import Callback, LearningRateMonitor\n",
    "from skimage.io import imread\n",
    "from sklearn.model_selection import GroupKFold, LeaveOneGroupOut\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
    "from torchmetrics import Accuracy, ConfusionMatrix\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision.models import ResNet50_Weights, resnet50\n",
    "from torchvision.transforms import (Compose, Normalize, RandAugment,\n",
    "                                    ToPILImage, ToTensor, TrivialAugmentWide)\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Train a facial expression model')\n",
    "# parser.add_argument(\"--param_version\", default='0', type=str)\n",
    "# parser.add_argument(\"--learning_rate\", default=0.01, type=float)\n",
    "# parser.add_argument(\"--total_steps\", default=10000, type=int)\n",
    "# parser.add_argument(\"--warmup_steps\", default=1000, type=int)\n",
    "# parser.add_argument(\"--cross_validation_fold\", default=0, type=int)\n",
    "# parser.add_argument(\"--shuffle\", default=0, type=int)\n",
    "# parser.add_argument(\"--cross_validation_folds\", default=9, type=int)\n",
    "# parser.add_argument(\"--weight_decay\", default=1e-4, type=float)\n",
    "# parser.add_argument(\"--warmup_decay\", default=0.0001, type=float)\n",
    "# parser.add_argument(\"--frames_per_set\", default=5, type=int)\n",
    "# parser.add_argument(\"--batch_size\", default=10, type=int)\n",
    "# parser.add_argument(\"--label_smoothing\", default=0.1, type=float)\n",
    "# parser.add_argument(\"--model\", default=\"deepset\", choices=[\"deepset\", \"resnet\"])\n",
    "# args = parser.parse_args()\n",
    "\n",
    "def load_data():\n",
    "    treatments_df = pd.read_csv(project_dir / 'data/raw/treatments_20230627.csv')\n",
    "\n",
    "    frames_folder_df = pd.DataFrame(dict(image=list(frames_dir.glob('*/*.png'))))\n",
    "    frames_folder_df['video'] = frames_folder_df.image.apply(lambda x: x.parts[-2])\n",
    "    frames_folder_df['mouse'] = frames_folder_df.video.apply(lambda x: re.match('([mf]\\d+)', x).group(1))\n",
    "    frames_folder_df['recording'] = frames_folder_df.video.apply(lambda x: int(re.match('.*rec(\\d+)', x).group(1)))\n",
    "\n",
    "    raw_videos_df = pd.read_csv(project_dir / 'data/raw/raw_videos_20230627.csv')\n",
    "    raw_videos_df.recording = raw_videos_df.recording.fillna(-1).astype(int)\n",
    "    raw_videos_df['video_time'] = raw_videos_df.apply(lambda x: f\"{x.hour:02}:{x.minutes:02}\", axis=1)\n",
    "    raw_videos_df['mouse'] = raw_videos_df.animal\n",
    "\n",
    "    combined_df = treatments_df.merge(frames_folder_df, how='left', on='mouse')\n",
    "    combined_df = combined_df.merge(raw_videos_df, how='left', on=['mouse', 'recording'])\n",
    "\n",
    "    combined_df = combined_df[combined_df.mouse != 'm18']\n",
    "    combined_df = combined_df[combined_df.treatment.isin(['high', 'saline'])]\n",
    "    combined_df = combined_df[combined_df.recording.isin([1, 4])]\n",
    "\n",
    "    # Label everything a 1\n",
    "    combined_df['label'] = np.ones(shape=combined_df.shape[0], dtype=int)\n",
    "\n",
    "    # Label control situations\n",
    "    combined_df.loc[combined_df.recording == 1, 'label'] = 0\n",
    "    combined_df.loc[combined_df.treatment == 'saline', 'label'] = 0\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "class MyIterDataset(IterableDataset):\n",
    "    def __init__(self, df, image_transform, frames_per_sample):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.video_groups = df.groupby('video')\n",
    "        agg = self.video_groups.agg({'video': 'first', 'label': 'first'})\n",
    "        self.videos = agg.video.tolist()\n",
    "        self.video_labels = agg.label\n",
    "        self.frames_per_sample = frames_per_sample\n",
    "        self.image_transform = image_transform\n",
    "            \n",
    "    def random_video(self):\n",
    "        index = random.randint(0, len(self.videos)-1)\n",
    "        return self.videos[index]\n",
    "    \n",
    "    def random_frames(self, video):\n",
    "        return self.video_groups.get_group(video).sample(self.frames_per_sample)\n",
    "        \n",
    "    def get_image(self, imagepath):\n",
    "        return self.image_transform(imread(imagepath))\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            video = self.random_video()\n",
    "            random_frames = self.random_frames(video)\n",
    "            label = random_frames.label.iloc[0]\n",
    "            out = {\n",
    "                'label': label,\n",
    "                'image': torch.stack(random_frames.image.apply(self.get_image).tolist())\n",
    "            }   \n",
    "            yield out\n",
    "    \n",
    "class TestableDataset(Dataset):\n",
    "    def __init__(self, iterable_dataloader, max_iterations=1000):\n",
    "        super().__init__()\n",
    "        self.iterable_dataloader = iterable_dataloader\n",
    "        self.max_iterations = max_iterations\n",
    "        self.init_iter()\n",
    "        \n",
    "    def init_iter(self):\n",
    "        self.iter_dataloader = iter(self.iterable_dataloader)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.max_iterations\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return next(self.iter_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Index\n",
      "['m3' 'm4' 'm5' 'm7' 'm9' 'm15' 'm16' 'f3' 'f7' 'f8' 'f10' 'f12' 'f16'\n",
      " 'f31' 'f32'] ['m12' 'm19' 'f1' 'f15']\n",
      "Split Index\n",
      "['m3' 'm7' 'm9' 'm12' 'm15' 'm19' 'f1' 'f3' 'f7' 'f8' 'f10' 'f12' 'f15'\n",
      " 'f31' 'f32'] ['m4' 'm5' 'm16' 'f16']\n",
      "Split Index\n",
      "['m3' 'm4' 'm5' 'm7' 'm9' 'm12' 'm15' 'm16' 'm19' 'f1' 'f8' 'f10' 'f12'\n",
      " 'f15' 'f16' 'f31' 'f32'] ['f3' 'f7']\n",
      "Split Index\n",
      "['m4' 'm5' 'm7' 'm12' 'm15' 'm16' 'm19' 'f1' 'f3' 'f7' 'f10' 'f15' 'f16'\n",
      " 'f31'] ['m3' 'm9' 'f8' 'f12' 'f32']\n",
      "Split Index\n",
      "['m3' 'm4' 'm5' 'm9' 'm12' 'm16' 'm19' 'f1' 'f3' 'f7' 'f8' 'f12' 'f15'\n",
      " 'f16' 'f32'] ['m7' 'm15' 'f10' 'f31']\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "\n",
    "# display(df.groupby('video').count()['image'])\n",
    "cv = StratifiedGroupKFold(5)\n",
    "splits = list(cv.split(df.index, groups=df.mouse, y=df.label))\n",
    "\n",
    "for split_index, split in enumerate(splits):\n",
    "    print('Split Index')\n",
    "# train, test = splits[config['cross_validation_fold']]\n",
    "    train, test = split\n",
    "    train_df = df.loc[df.index[train]]\n",
    "    test_df = df.loc[df.index[test]]\n",
    "    \n",
    "    print(train_df.mouse.unique(), test_df.mouse.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    2400\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    800\n",
       "1    200\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model_    | ResNet           | 21.3 M\n",
      "1 | fc        | Linear           | 4     \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "3 | metrics   | ModuleDict       | 0     \n",
      "-----------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6715812c7c14368ada0a0400acc20e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('val_tn', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('val_fn', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('val_tp', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('val_fp', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478604556bed49edaf5a30ea33f00c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_tn', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_fn', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_tp', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('train_fp', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b91d97920a847b987b8dcd6018dbb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dab4d11138489d8b4cfc7148c86e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41a55d68d434795825759ef46849dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116a8837e3574ee5b6e84331e194650a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20a7fd075ac444796408a4dae50715c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3aa5389e0344d68d54eadb25b05a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('test_tn', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('test_fn', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('test_tp', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n",
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('test_fp', ...)` in your `test_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.9968000054359436\n",
      "         test_fn                    0.0\n",
      "         test_fp            0.03200000151991844\n",
      "        test_loss           0.29229822754859924\n",
      "         test_tn            7.4679999351501465\n",
      "         test_tp                    2.5\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Split Index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5200\n",
       "1    2200\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    600\n",
       "1    400\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model_    | ResNet           | 21.3 M\n",
      "1 | fc        | Linear           | 4     \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "3 | metrics   | ModuleDict       | 0     \n",
      "-----------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ac948b329a4ef29d377dcaee22a09b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0862268cea40539a288a6d55c58538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b963d9fe9b464fbdd5592bb4f4a2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e6dc5d1d8b426fbeb01ce7e807a2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf93ee7ed434ba199551dd960d22c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5334f7a3dbb94054b2516574ca89ad9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb84320fbf140f7b307f605b6de6d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba79e378cfe4ffe9251ff489c9f895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.9998999834060669\n",
      "         test_fn           0.0010000000474974513\n",
      "         test_fp                    0.0\n",
      "        test_loss           0.2829274535179138\n",
      "         test_tn             7.484000205993652\n",
      "         test_tp             2.515000104904175\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Split Index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5200\n",
       "1    2000\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    600\n",
       "1    600\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model_    | ResNet           | 21.3 M\n",
      "1 | fc        | Linear           | 4     \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "3 | metrics   | ModuleDict       | 0     \n",
      "-----------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f076be7d8ee452baa4f0a2bff23f887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78256b099d140c18dbe9f1c52562b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b91ba6ecfa440668bece3af4113cdd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c47d3b1eb4b4b8cb444f64285d11a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ebacfac67c4bc1b6c12767818bde6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027458311358455e8719bba5647d4b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1bc0407eabb4420a3ac34daf38d4954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=5000` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38b5767c71194aadbcf18452958232ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "       Test metric             DataLoader 0\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "      test_accuracy         0.9936000108718872\n",
      "         test_fn                    0.0\n",
      "         test_fp            0.06400000303983688\n",
      "        test_loss           0.2867034673690796\n",
      "         test_tn             7.456999778747559\n",
      "         test_tp            2.4790000915527344\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Split Index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    5000\n",
       "1    2200\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    800\n",
       "1    400\n",
       "Name: image, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model_    | ResNet           | 21.3 M\n",
      "1 | fc        | Linear           | 4     \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "3 | metrics   | ModuleDict       | 0     \n",
      "-----------------------------------------------\n",
      "21.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.3 M    Total params\n",
      "85.141    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40bef1b3fa2459288759291f5383c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8318ae4832884e1a971a8aec756fa4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e198fdf5d9714a1a93ab7fda1b31a0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "247d09c696d8439a8631200109682dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andre/miniconda3/envs/mfe-berlin/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:52: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7057e2c98f1049e2b516dc279b5c6dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = dict(\n",
    "    param_version=0,\n",
    "    learning_rate=0.01,\n",
    "    total_steps=5000,\n",
    "    warmup_steps=200,\n",
    "    cross_validation_fold=0,\n",
    "    shuffle=0,\n",
    "    cross_validation_folds=9,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_decay=0.0001,\n",
    "    frames_per_set=5,\n",
    "    batch_size=10,\n",
    "    label_smoothing=0.1,\n",
    "    model='deepset'\n",
    ")\n",
    "\n",
    "df = load_data()\n",
    "cv = StratifiedGroupKFold(config['cross_validation_folds'])\n",
    "splits = list(cv.split(df.index, groups=df.mouse, y=df.label))\n",
    "\n",
    "for split_index, split in enumerate(splits):\n",
    "    print('Split Index')\n",
    "# train, test = splits[config['cross_validation_fold']]\n",
    "    train, test = split\n",
    "    train_df = df.loc[df.index[train]]\n",
    "    test_df = df.loc[df.index[test]]\n",
    "\n",
    "    from IPython.display import display\n",
    "    display(train_df.groupby('label').count()['image'])\n",
    "    display(test_df.groupby('label').count()['image'])\n",
    "\n",
    "    train_augmentation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToPILImage(),\n",
    "        torchvision.transforms.TrivialAugmentWide(),\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    test_augmentation = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = MyIterDataset(\n",
    "        train_df, frames_per_sample=config['frames_per_set'], image_transform=train_augmentation)\n",
    "    test_dataset = MyIterDataset(\n",
    "        test_df, frames_per_sample=config['frames_per_set'], image_transform=test_augmentation)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], num_workers=6)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=config['batch_size'], num_workers=6)\n",
    "\n",
    "    weights = sklearn.utils.class_weight.compute_class_weight(\n",
    "        'balanced', \n",
    "        classes=np.unique(train_dataset.video_labels),\n",
    "        y=train_dataset.video_labels\n",
    "    )\n",
    "            \n",
    "    loggers = [\n",
    "        # pl.loggers.WandbLogger()\n",
    "    ]\n",
    "    # for logger in loggers:\n",
    "    #     logger.log_hyperparams(config)\n",
    "        \n",
    "    callbacks = [\n",
    "        # LearningRateMonitor()\n",
    "    ]\n",
    "    trainer = pl.Trainer(\n",
    "        max_steps=config['total_steps'],\n",
    "        accelerator='gpu', devices=[0], \n",
    "        val_check_interval=1000, limit_val_batches=100,\n",
    "        logger = loggers,\n",
    "        enable_checkpointing=False,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    model_classes = dict(deepset=DeepSet)\n",
    "    model_class = model_classes[config['model']]\n",
    "    model = model_class(config, class_weights=torch.from_numpy(weights).float())\n",
    "    trainer.fit(model, train_dataloader, test_dataloader)\n",
    "    \n",
    "    actually_testable_dataset = TestableDataset(test_dataloader)\n",
    "    trainer.test(model, actually_testable_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
